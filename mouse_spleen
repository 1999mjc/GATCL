import torch
import pandas as pd
import numpy as np
import h5py
import anndata as ad
import scanpy as sc
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
from build_graph import *
from model import *

# --- Import necessary evaluation metrics (Assumed to be installed) ---
from sklearn.metrics import (
    homogeneity_score, mutual_info_score, v_measure_score,
    adjusted_mutual_info_score, normalized_mutual_info_score, adjusted_rand_score
)

def clr_normalize_each_cell(adata, inplace=True):
    """Normalize count vector for each cell, using Seurat's CLR method."""
    import numpy as np
    import scipy

    def seurat_clr(x):
        # Calculate geometric mean of log(x) and return CLR transformed value
        s = np.sum(np.log1p(x[x > 0]))
        exp = np.exp(s / len(x))
        return np.log1p(x / exp)

    if not inplace:
        adata = adata.copy()
    
    # Apply CLR transformation along axis 1 (per cell/row)
    adata.X = np.apply_along_axis(
        seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else np.array(adata.X))
    )
    return adata 
def compute_scores(true, pred):
    """Calculates all supervised clustering evaluation metrics."""
    return {
        "Homogeneity": homogeneity_score(true, pred),
        "Mutual_info": mutual_info_score(true, pred),
        "V_measure": v_measure_score(true, pred),
        "AMI": adjusted_mutual_info_score(true, pred),
        "NMI": normalized_mutual_info_score(true, pred),
        "ARI": adjusted_rand_score(true, pred)
    }
    
def run_example():
    """Runs the full GATCL workflow: data loading, preprocessing, training, clustering, and metric calculation."""
    
    # data
    RNA_DATA_PATH = "./data/mouse_spleen_rna" # Path to the RNA data file
    PROT_DATA_PATH = "./data/mouse_spleen_protein" # Path to the Protein/ATAC data file
    K_NEIGHBORS = N # K-Nearest Neighbors used for graph construction
    #TARGET_CLUSTERS = 10 # Target number of clusters
    # Load Data
    try:
        adata_rna = sc.read_h5ad(RNA_DATA_PATH)
        adata_prot = sc.read_h5ad(PROT_DATA_PATH)
    except FileNotFoundError:
        print("\nERROR: Data files not found. Please check paths.")
        return
        
    # --- Start Standard Data Preprocessing Pipeline ---
    
    # RNA: 1. Filter low-expressed genes
    sc.pp.filter_genes(adata_rna, min_cells=10)
    # RNA: 2. Normalize and log-transform
    sc.pp.normalize_total(adata_rna)
    sc.pp.log1p(adata_rna)
    # RNA: 3. Select highly variable genes (HVG)
    sc.pp.highly_variable_genes(adata_rna, n_top_genes=3000)
    adata_rna = adata_rna[:, adata_rna.var['highly_variable']].copy()
    
    # Protein:  Apply CLR normalization
    clr_normalize_each_cell(adata_prot)
    
    # 5. Apply PCA for final feature generation 
    PCA_COMPONENTS = adt_adata.n_vars-1  ##choose the proper number
    sc.tl.pca(adata_rna, n_comps=PCA_COMPONENTS)
    sc.tl.pca(adata_prot, n_comps=PCA_COMPONENTS)
    
    # 6. Set final feature representations in obsm['feat'] for model input
    adata_rna.obsm['feat'] = adata_rna.obsm["X_pca"]
    adata_prot.obsm['feat'] = adata_prot.obsm["X_pca"]
    
    # --- Check for Necessary Features (after preprocessing) ---
    if 'feat' not in adata_rna.obsm or 'spatial' not in adata_rna.obsm:
        print("\nERROR: AnnData objects must contain 'feat' (embeddings/PCA) and 'spatial' (coordinates) in .obsm")
        print("Please ensure spatial coordinates are available.")
        return

    N_SPOTS = adata_rna.n_obs
    print(f"Data Loaded: {N_SPOTS} Spots.")
    
    # 2. Graph Construction
    data_pkg = build_graphs(adata_rna, adata_prot, n_neighbors=K_NEIGHBORS)
    
    # 3. Model Instantiation and Training (Assumes GATCL_Trainer is defined)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Use GPU if available
    trainer = GATCL_Trainer(
        data=data_pkg,
        device=device
    )
    
    # 4. Execute Training, get final embedding
    output = trainer.train()
    final_embedding = output['embedding']
    
    # 5. Save embedding result
    np.save("combine_embedding.npy", final_embedding)
    np.save(" alpha_1.npy", output['alpha_1'])
    np.save(" alpha_2.npy", output['alpha_2'])
    np.save(" alpha_cross.npy", output['alpha_cross'])
    np.savetxt("embedding.csv", embedding, delimiter=",",  fmt='%.6f')
    ########################################################
    # --- Clustering(RStudio)
    # Define the path to the input data file.
    data_file <- "embedding.csv"

     # 2. Install and load necessary R packages (if not already installed)
     # Check if the 'mclust' package is installed.
     if (!requireNamespace("mclust", quietly = TRUE)) {
      # If not installed, install the package.
        install.packages("mclust")
       }
     # Load the 'mclust' library for model-based clustering.
     library(mclust)

     # 3. Set a random seed to ensure reproducible results
     # Set a specific seed for random number generation.
     set.seed(2020) 

     # 4. Read the data
     # Print a message indicating data reading is in progress.
     cat("reading data...\n")
     # Read the data into an R data frame. header=FALSE indicates no header, sep="," uses comma as delimiter.
     data_for_clustering <- read.csv(data_file, header=FALSE, sep=",")

     # 5. Execute Mclust clustering
     # Define the desired number of clusters (K).
     K <- 5 # choose a value you want 
     # Print a message about the start of clustering, including the value of K.
     cat(paste(" Mclust clusteringï¼ŒK =", K, "...\n"))

     # Execute the clustering process using Mclust (Gaussian Mixture Models).
     # G = K sets the number of components. modelNames = "EEE" specifies an ellipsoidal model with equal shape and equal orientation.
     mclust_result <- Mclust(data_for_clustering, G = K, modelNames = "EEE")

     # 6. Output and save clustering results
     # Print a confirmation message.
     cat("Mclust finishe!\n\n")

     # View summary information (optional, for checking results)
     # Display a summary of the Mclust results.
     summary(mclust_result)

     # Extract the resulting cluster assignments (labels) into a vector.
     cluster_labels <- mclust_result$classification

     # 2. Define the output filename
     # Define the path for the output CSV file.
     csv_output_file <- "mclust_classification_results_R.csv"

     # 1) Convert the cluster labels vector into a single-column data frame.
     data_to_save <- data.frame(cluster_label = cluster_labels)

     # 2) Use write.csv() function to save the data frame to a CSV file.
     # The data frame to be saved.
     write.csv(
     # The output file path.
          data_to_save,
          file = csv_output_file,
        row.names = FALSE
        )
######################################################################
    #######calculate the evaluation metrics
    # Load the predicted cluster labels saved from the R script (or previous step).
    labels = pd.read_csv('mclust_classification_results_R.csv')

    # Load the ground truth annotations from an Excel file.
    annotation = pd.read_excel(
    # Specify the full path to the annotation file.
           "./data/annotiation.xlsx"
    )

    # Extract true labels (ground truth) from the 'manual' column of the annotation DataFrame.
    true_labels2 = annotation['manual']
    # Assign predicted labels (the entire 'labels' DataFrame/single column) to pred_labels2.
    pred_labels2 = labels  # The name corresponds to the column saved previously.
    # Convert the Pandas DataFrame (pred_labels2) to a NumPy array.
    pred_labels2 = pred_labels2.to_numpy()
    # Flatten the NumPy array to ensure it is a 1D vector, which is required by clustering evaluation functions.
    pred_labels2 = pred_labels2.flatten()  # Recommended, returns a copy.
    # Calculate clustering evaluation scores (ARI, NMI, etc.) using the custom function.
    scores_gatcl = compute_scores(true_labels2, pred_labels2)
    # Convert the dictionary of scores into a Pandas DataFrame for easy saving.
    df_scores = pd.DataFrame(list(scores_gatcl.items()), columns=['Metric', 'Score'])

    # Save the calculated evaluation metrics to an Excel file.
    # df_scores.to_excel(
    # # Specify the output path and filename for the results.
    #         "GATCL_result.xlsx",
    #    index=False
    #  )
        
    #####spatial domain picture
    # Read the corresponding AnnData, extracting spot names as the index.
    barcodes = adata_rna.obs_names
    # Add the cluster labels to the AnnData's observation metadata (adata_rna.obs).
    adata_rna.obs["cluster_labels"] = labels.astype(str)  # Convert to string type for easier plotting/handling.

    # Get the spatial coordinates from the AnnData object's .obsm slot.
    coords = adata_rna.obsm["spatial"]

    # Generate the base color list.
    # Determine the number of unique clusters present in the labels.
    num_clusters = len(np.unique(labels))
    # Get a base colormap (tab10 is a common categorical map) with enough colors for the clusters.
    base_cmap = plt.cm.get_cmap('tab10', num_clusters)
    # Generate a list of color codes (RGBA tuples) from the base colormap.
    base_colors = [base_cmap(i) for i in range(num_clusters)]

    # 2. Define custom color order - adjust the index order as needed here
    # Define a custom sequence of indices to rearrange the base colors.
    custom_order = [0,1,2,3,4]  # This order can be modified as required.

    # Apply the custom order to get the final list of colors used for plotting.
    # Select and reorder colors based on the custom_order indices.
    custom_colors = [base_colors[i] for i in custom_order]

    # 3. Assign color to each point (match custom colors by cluster label)
    # Map the custom colors to each data point based on its cluster label.
    point_colors = [custom_colors[label] for label in labels]

    # 4. Draw spatial plot (add color legend)
    # Create a new figure object with specified size.
    plt.figure(figsize=(6, 5))
    # Draw the scatter plot using coordinates for position and point_colors for color.
    plt.scatter(coords[:, 0], coords[:, 1], c=point_colors, s=30)
    # Invert the Y-axis (a common convention in spatial transcriptomics data visualization).
    plt.gca().invert_yaxis()
    # Turn off the coordinate axes for a cleaner look.
    plt.axis('off')

    #####  Violin picture
    # Load the NumPy array containing modality weights from the file.
    alpha_omics1 = np.load("alpha_omics1.npy")
    # Convert the NumPy array into a Pandas DataFrame.
    alpha_omics1 = pd.DataFrame(alpha_omics1)
    # Concatenate the alpha_omics1 DataFrame and the existing DataFrame 'df' column-wise.
    df_all = pd.concat([alpha_omics1,df],axis=1)
    # Remove the 'Barcode' column from the combined DataFrame in place.
    df_all.drop(columns=['Barcode'], inplace=True)
    # Rename the first three columns to represent the weights and cluster labels.
    df_all.columns.values[0:3] = ['spatial_weight', 'omics_weight','cluster_label']
    # Step 0: Ensure cluster_label is integer and sort by it
    # Convert the 'cluster_label' column to integer type.
    df_all['cluster_label'] = df_all['cluster_label'].astype(int)
    # Sort the entire DataFrame based on the 'cluster_label' column values.
    df_all = df_all.sort_values('cluster_label')

    # Step 1: Convert to long format suitable for plotting
    # Unpivot the DataFrame from wide to long format.
    df_rna = df_all.melt(id_vars='cluster_label',value_vars=['spatial_weight', 'omics_weight'], var_name='Modality',
    # Name the new column that will store the actual weight values.
                     value_name='Weight')

    # Step 2: Rename Modality names for friendlier display
    # Define a mapping dictionary to rename modality labels.
    modality_map = {
       'spatial_weight': 'Spatial graph',
       'omics_weight': 'Feature graph'
    }
    # Apply the mapping to the 'Modality' column in the long-format DataFrame.
    df_rna['Modality'] = df_rna['Modality'].map(modality_map)

   # Step 3: Set plotting style
   # Set the Seaborn style to 'whitegrid' for better aesthetics.
   sns.set(style="whitegrid")

   # Step 4: Create plotting object
   # Create a new figure with a specified size (6 inches wide, 4 inches tall).
   plt.figure(figsize=(6, 4))

   # Step 5: Draw violin plot (Protein part)
   # Draw the violin plot using the processed long-format DataFrame.
   sns.violinplot(data=df_rna,
               x='cluster_label', y='Weight',
               hue='Modality',
               split=True,
               inner='quartile',
               palette=['#1f77b4', '#ff7f0e'])
   # Set the main title of the plot. Note: Title indicates 'Protein' weights.
   plt.title("Modality weight (Protein)", fontsize=14, weight='bold')
   # Remove the X-axis title/label.
   plt.xlabel("")
   # Remove the Y-axis title/label.
   plt.ylabel("")
   # Customize the legend position (below the plot) and layout.
   plt.legend(title='', loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=2, fontsize=12)
   # Adjust plot parameters for a tight layout to prevent clipping.
   plt.tight_layout()
   # Display the plot window.
   plt.show()
###DEG
   # Rename the first column of the loaded labels to 'barcode' for merging
   labels = labels.rename(columns={labels.columns[0]: 'barcode'})
   # Add 'barcode' column to adata.obs, using the existing observation names (which are often the cell barcodes)
   adata = adata_rna
   adata.obs['barcode'] = adata.obs_names
   # Merge cluster labels into adata.obs based on 'barcode'
   adata.obs = adata.obs.merge(labels, on='barcode', how='left')
   # Assign cluster labels to a new field 'GATCL', converting to string type
   adata.obs['GATCL'] = adata.obs['GCNCL_5'].astype(str)
   # Set raw data if not already set (important for rank_genes_groups to use pre-normalized/log data if needed, or just for backup)
   if adata.raw is None:
      adata.raw = adata
   # --- 2. Differential Gene Expression Analysis ---
   # Calculate differentially expressed genes (DEGs) for each cluster using Wilcoxon rank-sum test
   sc.tl.rank_genes_groups(adata, groupby='GATCL', method='wilcoxon')
   # --- 3. Extracting Top Genes ---
   # Define how many top genes to extract per cluster
   top_n = 7
   # Get unique cluster names
   groups = adata.obs['GATCL'].unique().tolist()
   top_genes = []
   # Loop through each group (cluster) to extract the top 'top_n' genes
   for group in groups:
     # Extract the top genes based on the rank_genes_groups results
     top = adata.uns['rank_genes_groups']['names'][group][:top_n]
     top_genes.extend(top)
   # Remove duplicate genes across all clusters
     top_genes = list(set(top_genes))
  # --- 4. Data Preparation for Heatmap ---
  # Extract the expression matrix for the selected top genes (using the raw/preprocessed data)
    expr = pd.DataFrame(adata.raw[:, top_genes].X.toarray(),
                        index=adata.obs_names,
                        columns=top_genes)
   # Add cluster information to the expression DataFrame
   expr['cluster'] = adata.obs['GATCL']
   # Calculate the mean expression for each gene within each cluster
    cluster_mean_expr = expr.groupby('cluster').mean()
   # --- 5. Z-Score Standardization and Gene Ordering ---
   # Standardize the mean expression across genes (rows) for each gene's expression relative to its mean across all clusters (Z-score)
   # .T transposes so that genes are rows and clusters are columns for the apply function
   # axis=1 applies the Z-score calculation row-wise (per gene)
   cluster_mean_expr_z = cluster_mean_expr.T.apply(lambda x: (x - x.mean()) / x.std(), axis=1)
   # Determine the order of genes based on which cluster has the highest standardized expression for that gene
   # idxmax(axis=1) finds the column (cluster) index with the maximum value for each row (gene)
   # .sort_values() sorts the genes based on these maximum cluster indices (resulting in a logical ordering for visualization)
   gene_order = cluster_mean_expr_z.idxmax(axis=1).sort_values()
   # Reorder the rows (genes) of the standardized expression matrix based on the determined order
   cluster_mean_expr_z_sorted = cluster_mean_expr_z.loc[gene_order.index]
   # --- 6. Visualization --
   # Set up the figure size
   plt.figure(figsize=(16, 6))
   # Create the heatmap: rows are genes, columns are clusters, colors represent Z-scores
   sns.heatmap(cluster_mean_expr_z_sorted, cmap="coolwarm", yticklabels=True)
   plt.xlabel("Cluster")
   plt.ylabel("Gene")
   # plt.title("Top Differential Genes per Cluster (sorted)") # Title is commented out in original
   plt.tight_layout() # Adjust layout to prevent labels from overlapping
   # Save the figure with high resolution
   plt.show()

if __name__ == "__main__":
    # Ensure all auxiliary functions (like GATCL_Trainer, build_graphs, etc.) are imported or defined before running
    run_example()
